✅ DeepSeek-R1 with Ollama for local LLM inference
✅ LangChain for structured prompt management
✅ Streamlit for an interactive UI
✅ Session management for contextual responses

This project serves as a foundation for understanding LLM deployment, structured prompting, and AI-driven coding assistance. Over the next two weeks, I’ll be exploring advanced functionalities such as fine-tuning, memory management, and multi-modal integration.
